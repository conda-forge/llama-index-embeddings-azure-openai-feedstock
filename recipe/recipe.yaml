context:
  version: "0.3.2"

package:
  name: llama-index-embeddings-azure-openai
  version: ${{ version }}

source:
  - url: https://pypi.org/packages/source/l/llama-index-embeddings-azure-openai/llama_index_embeddings_azure_openai-${{ version }}.tar.gz
    sha256: 0f7cad33e92450c4e9e7e470bd97c1dc227bee7a859f5ae90ce17b9a3d3b34e0
  - url: https://raw.githubusercontent.com/run-llama/llama_index/main/LICENSE
    sha256: 24f40b5190fdacabc24ddbb5f76364d15e4f030925220ea300d8a2dd4993c8cb

build:
  number: 0
  noarch: python
  script: ${{ PYTHON }} -m pip install .

requirements:
  host:
    - python ${{ python_min }}.*
    - pip
    - poetry-core
  run:
    - python >=${{ python_min }}
    - llama-index-llms-azure-openai <0.4.0,>=0.3.0
    - llama-index-embeddings-openai <0.4.0,>=0.3.0
    - llama-index-core <0.13.0,>=0.12.0

tests:
  - python:
      imports:
        - llama_index.embeddings.azure_openai
      pip_check: true
      python_version: ${{ python_min }}.*

about:
  homepage: https://github.com/run-llama/llama_index
  summary: llama-index embeddings azure openai integration
  license: MIT
  license_file: LICENSE

extra:
  recipe-maintainers:
    - moritzwilksch
